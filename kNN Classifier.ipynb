{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3073)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Images = []\n",
    "\n",
    "imgDog = []\n",
    "for files in os.walk('animals/dogs'):\n",
    "    for d in files[2]:\n",
    "        imgd = cv2.imread('animals/dogs/'+d)\n",
    "        imgd = cv2.resize(imgd,dsize=(32,32))\n",
    "        imgd = np.ravel(imgd)\n",
    "        imgDog.append(imgd)\n",
    "imgDog = np.array(imgDog)\n",
    "yd = np.full((1000,1), 0) \n",
    "imglDog = np.append(imgDog,yd,axis=1)\n",
    "Images.extend(imglDog)\n",
    "\n",
    "\n",
    "imgCat = []\n",
    "for files in os.walk('animals/cats'):\n",
    "    for c in files[2]:\n",
    "        imgc = cv2.imread('animals/cats/'+c)\n",
    "        imgc = cv2.resize(imgc,dsize=(32,32))\n",
    "        imgc = np.ravel(imgc)\n",
    "        imgCat.append(imgc)\n",
    "imgCat = np.array(imgCat)\n",
    "yc = np.full((1000,1), 1)\n",
    "imglCat = np.append(imgCat,yc,axis=1)\n",
    "Images.extend(imglCat)\n",
    "\n",
    "\n",
    "imgPanda = []\n",
    "for files in os.walk('animals/panda'):\n",
    "    for p in files[2]:\n",
    "        imgp = cv2.imread('animals/panda/'+p)\n",
    "        imgp = cv2.resize(imgp,dsize=(32,32))\n",
    "        imgp = np.ravel(imgp)\n",
    "        imgPanda.append(imgp)\n",
    "imgPanda = np.array(imgPanda)\n",
    "yp = np.full((1000,1), 2)\n",
    "imglPanda = np.append(imgPanda,yp,axis=1)\n",
    "Images.extend(imglPanda)\n",
    "X = np.array(Images) \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of Train set (1800, 3073)\n",
      "The size of Test set (900, 3073)\n",
      "The size of Validation set (300, 3073)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.shuffle(X)\n",
    "train, validate, test = np.split(X, [int(.6 * len(X)), int(.7 * len(X))])\n",
    "\n",
    "print('The size of Train set' ,train.shape)\n",
    "print('The size of Test set' ,test.shape)\n",
    "print('The size of Validation set' ,validate.shape)\n",
    "\n",
    "\n",
    "trainX, trainY = (train[:, :-1], train[:, -1])\n",
    "testX, testY = (test[:, :-1], test[:, -1])\n",
    "valX, valY = (validate[:, :-1], validate[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distmatrix=[]\n",
    "distList = []\n",
    "\n",
    "for a in range(0,len(testX)):\n",
    "    distList = []\n",
    "    for b in range (0,len(trainX)):\n",
    "        distList.append(sum(abs(trainX[b] - testX[a])))\n",
    "    distmatrix.append(distList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k_list = [10,50,150,200,250,300,350,400,500];\n",
    "Apreds = []\n",
    "for k in k_list:\n",
    "    preds=[]\n",
    "    for j in range(0,len(distmatrix)):\n",
    "        list12 = []\n",
    "        for i in range(0,len(distmatrix[j])):\n",
    "            list12.append((distmatrix[j][i],trainY[i]))\n",
    "            list12 = sorted(list12, key=lambda a_entry: a_entry[0])[:k]\n",
    "            for l in range(0,len(list12)):\n",
    "                fin_list = []\n",
    "                fin_list.append(list12[l][1])\n",
    "        preds.append((max(set(fin_list), key=fin_list.count)))\n",
    "    Apreds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Classification Report for k = 10\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.45      0.39       277\n",
      "           1       0.36      0.49      0.42       294\n",
      "           2       0.73      0.33      0.45       329\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       900\n",
      "   macro avg       0.48      0.42      0.42       900\n",
      "weighted avg       0.49      0.42      0.42       900\n",
      "\n",
      "The Accuracy is = \n",
      "\n",
      " 0.4177777777777778\n",
      "\n",
      "The Confusion Matrix is = \n",
      "\n",
      " [[125 132  20]\n",
      " [132 143  19]\n",
      " [102 119 108]]\n",
      "\n",
      "The Classification Report for k = 50\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.52      0.41       277\n",
      "           1       0.35      0.41      0.38       294\n",
      "           2       0.67      0.29      0.40       329\n",
      "\n",
      "   micro avg       0.40      0.40      0.40       900\n",
      "   macro avg       0.46      0.40      0.40       900\n",
      "weighted avg       0.47      0.40      0.40       900\n",
      "\n",
      "The Accuracy is = \n",
      "\n",
      " 0.3977777777777778\n",
      "\n",
      "The Confusion Matrix is = \n",
      "\n",
      " [[143 114  20]\n",
      " [147 121  26]\n",
      " [125 110  94]]\n",
      "\n",
      "The Classification Report for k = 150\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.48      0.40       277\n",
      "           1       0.35      0.36      0.36       294\n",
      "           2       0.55      0.35      0.43       329\n",
      "\n",
      "   micro avg       0.39      0.39      0.39       900\n",
      "   macro avg       0.41      0.40      0.39       900\n",
      "weighted avg       0.42      0.39      0.40       900\n",
      "\n",
      "The Accuracy is = \n",
      "\n",
      " 0.3933333333333333\n",
      "\n",
      "The Confusion Matrix is = \n",
      "\n",
      " [[132 101  44]\n",
      " [137 107  50]\n",
      " [114 100 115]]\n",
      "\n",
      "The Classification Report for k = 200\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.39      0.35       277\n",
      "           1       0.35      0.37      0.36       294\n",
      "           2       0.50      0.36      0.42       329\n",
      "\n",
      "   micro avg       0.37      0.37      0.37       900\n",
      "   macro avg       0.39      0.37      0.37       900\n",
      "weighted avg       0.39      0.37      0.38       900\n",
      "\n",
      "The Accuracy is = \n",
      "\n",
      " 0.37222222222222223\n",
      "\n",
      "The Confusion Matrix is = \n",
      "\n",
      " [[109 115  53]\n",
      " [123 109  62]\n",
      " [122  90 117]]\n",
      "\n",
      "The Classification Report for k = 250\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.41      0.36       277\n",
      "           1       0.34      0.39      0.36       294\n",
      "           2       0.50      0.32      0.39       329\n",
      "\n",
      "   micro avg       0.37      0.37      0.37       900\n",
      "   macro avg       0.39      0.37      0.37       900\n",
      "weighted avg       0.39      0.37      0.37       900\n",
      "\n",
      "The Accuracy is = \n",
      "\n",
      " 0.3711111111111111\n",
      "\n",
      "The Confusion Matrix is = \n",
      "\n",
      " [[114 111  52]\n",
      " [128 114  52]\n",
      " [114 109 106]]\n",
      "\n",
      "The Classification Report for k = 300\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.43      0.39       277\n",
      "           1       0.38      0.41      0.39       294\n",
      "           2       0.52      0.37      0.43       329\n",
      "\n",
      "   micro avg       0.40      0.40      0.40       900\n",
      "   macro avg       0.41      0.40      0.40       900\n",
      "weighted avg       0.42      0.40      0.40       900\n",
      "\n",
      "The Accuracy is = \n",
      "\n",
      " 0.4022222222222222\n",
      "\n",
      "The Confusion Matrix is = \n",
      "\n",
      " [[120 106  51]\n",
      " [111 120  63]\n",
      " [115  92 122]]\n",
      "\n",
      "The Classification Report for k = 350\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.46      0.39       277\n",
      "           1       0.36      0.37      0.36       294\n",
      "           2       0.50      0.34      0.41       329\n",
      "\n",
      "   micro avg       0.39      0.39      0.39       900\n",
      "   macro avg       0.40      0.39      0.39       900\n",
      "weighted avg       0.40      0.39      0.39       900\n",
      "\n",
      "The Accuracy is = \n",
      "\n",
      " 0.3877777777777778\n",
      "\n",
      "The Confusion Matrix is = \n",
      "\n",
      " [[127  95  55]\n",
      " [125 109  60]\n",
      " [116 100 113]]\n",
      "\n",
      "The Classification Report for k = 400\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.44      0.40       277\n",
      "           1       0.34      0.33      0.33       294\n",
      "           2       0.42      0.36      0.39       329\n",
      "\n",
      "   micro avg       0.38      0.38      0.38       900\n",
      "   macro avg       0.38      0.38      0.37       900\n",
      "weighted avg       0.38      0.38      0.37       900\n",
      "\n",
      "The Accuracy is = \n",
      "\n",
      " 0.37555555555555553\n",
      "\n",
      "The Confusion Matrix is = \n",
      "\n",
      " [[123  79  75]\n",
      " [111  96  87]\n",
      " [100 110 119]]\n",
      "\n",
      "The Classification Report for k = 500\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.41      0.36       277\n",
      "           1       0.34      0.34      0.34       294\n",
      "           2       0.44      0.34      0.38       329\n",
      "\n",
      "   micro avg       0.36      0.36      0.36       900\n",
      "   macro avg       0.37      0.36      0.36       900\n",
      "weighted avg       0.37      0.36      0.36       900\n",
      "\n",
      "The Accuracy is = \n",
      "\n",
      " 0.3622222222222222\n",
      "\n",
      "The Confusion Matrix is = \n",
      "\n",
      " [[113  92  72]\n",
      " [123 101  70]\n",
      " [116 101 112]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for d in range(0,len(Apreds)):\n",
    "    z = np.asarray(Apreds[d])\n",
    "    z = np.reshape(z,(900))\n",
    "    print(\"\\nThe Classification Report for k = \" + str(k_list[d]) +\"\\n\\n\", sklearn.metrics.classification_report(testY, z)) \n",
    "    print(\"The Accuracy is = \\n\\n\", sklearn.metrics.accuracy_score(testY, z))\n",
    "    print(\"\\nThe Confusion Matrix is = \\n\\n\", sklearn.metrics.confusion_matrix(testY,z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "distmatrix1=[]\n",
    "distList1 = []\n",
    "\n",
    "for a1 in range(0,len(valX)):\n",
    "    distList1 = []\n",
    "    for b1 in range (0,len(trainX)):\n",
    "        distList1.append(sum(abs(trainX[b1] - valX[a1])))\n",
    "    distmatrix1.append(distList1)\n",
    "\n",
    "len(distmatrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k1 = 300\n",
    "Apreds1 = []\n",
    "preds1 = []\n",
    "for j1 in range(0,len(distmatrix1)):\n",
    "    list22 = []\n",
    "    for i1 in range(0,len(distmatrix1[j1])):\n",
    "        list22.append((distmatrix1[j1][i1],trainY[i1]))\n",
    "        list22 = sorted(list22, key=lambda a_entry: a_entry[0])[:k1]\n",
    "        for l1 in range(0,len(list22)):\n",
    "            fin_list1 = []\n",
    "            fin_list1.append(list22[l1][1])\n",
    "    preds1.append((max(set(fin_list1), key=fin_list1.count)))\n",
    "Apreds1.append(preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Classification Report for Validation Set with K = 300 is\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.41      0.38       104\n",
      "           1       0.33      0.35      0.34       101\n",
      "           2       0.36      0.27      0.31        95\n",
      "\n",
      "   micro avg       0.35      0.35      0.35       300\n",
      "   macro avg       0.35      0.34      0.34       300\n",
      "weighted avg       0.35      0.35      0.34       300\n",
      "\n",
      "The Accuracy is = \n",
      "\n",
      " 0.3466666666666667\n",
      "\n",
      "The Confusion Matrix is = \n",
      "\n",
      " [[43 38 23]\n",
      " [43 35 23]\n",
      " [37 32 26]]\n"
     ]
    }
   ],
   "source": [
    "z1 = np.asarray(Apreds1)\n",
    "z1 = np.reshape(z1,(300))\n",
    "print(\"\\nThe Classification Report for Validation Set with K = \"+ str(k1) +\" is\\n\\n \", sklearn.metrics.classification_report(valY, z1)) \n",
    "print(\"The Accuracy is = \\n\\n\", sklearn.metrics.accuracy_score(valY, z1))\n",
    "print(\"\\nThe Confusion Matrix is = \\n\\n\", sklearn.metrics.confusion_matrix(valY,z1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
